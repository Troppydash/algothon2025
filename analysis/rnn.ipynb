{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f18d79c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\algothon2025\\\\algothon2025'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# Get the current script's directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91793031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from ta.momentum import RSIIndicator, StochasticOscillator, ROCIndicator, WilliamsRIndicator\n",
    "from ta.trend import MACD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3ec9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "330b55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import COMMISSION_RATE, extract_features2\n",
    "BEFORE = 20\n",
    "AHEAD = 40\n",
    "TA_WINDOW = 50\n",
    "\n",
    "# Per stock extraction\n",
    "def split_seq(price_data: pd.DataFrame, stock: int):\n",
    "    length = price_data[stock].shape[0]\n",
    "    price_data.index = list(range(length))\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    rsi_series, rsi_series2, macd_signal, macd_signal2, macd_signal3, \\\n",
    "        stoch_sign, stoch_sign2, roc_vals, roc_vals2, roc_vals3, \\\n",
    "        williamR_vals, williamR_vals2 = extract_features2(price_data[stock])\n",
    "    # print(rsi_series)\n",
    "    # print(rsi_series.shape)\n",
    "    for i in range(TA_WINDOW + BEFORE - 1, length - AHEAD):\n",
    "        # Try 1 price/pct: Accuracy 0.57%, seems to do 0R\n",
    "        # Try all price/pct: Overfit\n",
    "        # X.append(price_data.iloc[(i - BEFORE + 1):(i+1), :].pct_change().dropna().to_numpy().reshape((BEFORE - 1, -1)))\n",
    "        \n",
    "        # Try feature extractions for single price\n",
    "        current = []\n",
    "        for j in range(BEFORE):\n",
    "            current.append([rsi_series[i-j], rsi_series2[i-j],\n",
    "                            macd_signal[i-j], macd_signal2[i-j], macd_signal3[i-j],\n",
    "                            stoch_sign[i-j], stoch_sign2[i-j],\n",
    "                            roc_vals[i-j], roc_vals2[i-j], roc_vals3[i-j],\n",
    "                            williamR_vals[i-j], williamR_vals2[i-j]])\n",
    "        X.append(np.array(current))\n",
    "        return_pct = (price_data[stock][i+AHEAD] - price_data[stock][i]) / price_data[stock][i]\n",
    "        if abs(return_pct) < COMMISSION_RATE:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            if return_pct > 0:\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(-1)\n",
    "    # print(X)\n",
    "    X_df = np.array(X)\n",
    "    y_df = np.array(y)\n",
    "    y_df = tf.one_hot(y_df + 1, depth=3)\n",
    "    return X_df, y_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6708915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../prices.txt\", sep=\"\\\\s+\", header=None, index_col=None)\n",
    "df.index = np.arange(df.shape[0])\n",
    "df.rename(columns=lambda c: int(c), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "383a460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df.shape[0]\n",
    "train = df.iloc[:int(total * 0.75)]\n",
    "test = df.iloc[int(total * 0.75):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f59c906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(641, 20, 12)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOCK = 5\n",
    "X_train, y_train = split_seq(train, STOCK)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d72af441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5.47438536e+01,  5.22925710e+01,  3.19560076e-02, ...,\n",
       "         -2.78164117e-01, -1.25000000e+01, -2.53333333e+01],\n",
       "        [ 5.83344507e+01,  5.38667444e+01,  3.69707443e-02, ...,\n",
       "          4.18994413e-01, -0.00000000e+00, -2.72727273e+01],\n",
       "        [ 5.42867625e+01,  5.17990665e+01,  3.13439704e-02, ...,\n",
       "          0.00000000e+00, -0.00000000e+00, -4.85148515e+01],\n",
       "        ...,\n",
       "        [ 4.04492599e+01,  4.82606394e+01, -6.22870215e-02, ...,\n",
       "         -3.83408853e-01, -1.00000000e+02, -8.62385321e+01],\n",
       "        [ 4.34619908e+01,  5.01561553e+01, -4.91329371e-02, ...,\n",
       "         -6.23484586e-01, -9.43181818e+01, -7.61467890e+01],\n",
       "        [ 4.88167641e+01,  5.34176972e+01, -2.91840410e-02, ...,\n",
       "         -4.48275862e-01, -7.38636364e+01, -5.28455285e+01]],\n",
       "\n",
       "       [[ 4.70943770e+01,  4.87322566e+01,  1.56480261e-02, ...,\n",
       "         -6.62482566e-01, -4.21875000e+01, -4.21875000e+01],\n",
       "        [ 5.47438536e+01,  5.22925710e+01,  3.19560076e-02, ...,\n",
       "         -2.78164117e-01, -1.25000000e+01, -2.53333333e+01],\n",
       "        [ 5.83344507e+01,  5.38667444e+01,  3.69707443e-02, ...,\n",
       "          4.18994413e-01, -0.00000000e+00, -2.72727273e+01],\n",
       "        ...,\n",
       "        [ 3.40180994e+01,  4.39674328e+01, -7.96727777e-02, ...,\n",
       "         -9.44716585e-01, -1.00000000e+02, -1.00000000e+02],\n",
       "        [ 4.04492599e+01,  4.82606394e+01, -6.22870215e-02, ...,\n",
       "         -3.83408853e-01, -1.00000000e+02, -8.62385321e+01],\n",
       "        [ 4.34619908e+01,  5.01561553e+01, -4.91329371e-02, ...,\n",
       "         -6.23484586e-01, -9.43181818e+01, -7.61467890e+01]],\n",
       "\n",
       "       [[ 4.16490349e+01,  4.59585684e+01, -2.99175779e-03, ...,\n",
       "         -5.61600562e-01, -6.71875000e+01, -6.71875000e+01],\n",
       "        [ 4.70943770e+01,  4.87322566e+01,  1.56480261e-02, ...,\n",
       "         -6.62482566e-01, -4.21875000e+01, -4.21875000e+01],\n",
       "        [ 5.47438536e+01,  5.22925710e+01,  3.19560076e-02, ...,\n",
       "         -2.78164117e-01, -1.25000000e+01, -2.53333333e+01],\n",
       "        ...,\n",
       "        [ 3.13514072e+01,  4.20706236e+01, -8.89002499e-02, ...,\n",
       "         -4.59201696e-01, -1.00000000e+02, -1.00000000e+02],\n",
       "        [ 3.40180994e+01,  4.39674328e+01, -7.96727777e-02, ...,\n",
       "         -9.44716585e-01, -1.00000000e+02, -1.00000000e+02],\n",
       "        [ 4.04492599e+01,  4.82606394e+01, -6.22870215e-02, ...,\n",
       "         -3.83408853e-01, -1.00000000e+02, -8.62385321e+01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.23131452e+01,  4.95184668e+01, -3.85949952e-02, ...,\n",
       "          0.00000000e+00, -1.00000000e+02, -1.00000000e+02],\n",
       "        [ 4.23131452e+01,  4.95184668e+01, -3.81262711e-02, ...,\n",
       "         -1.04895105e-01, -1.00000000e+02, -7.42424242e+01],\n",
       "        [ 4.34678237e+01,  5.01612230e+01, -3.13563040e-02, ...,\n",
       "         -4.52488688e-01, -1.00000000e+02, -6.96969697e+01],\n",
       "        ...,\n",
       "        [ 6.50380532e+01,  5.93989895e+01,  4.02848734e-02, ...,\n",
       "         -2.42718447e-01, -1.09375000e+01, -8.64197531e+00],\n",
       "        [ 6.91577174e+01,  6.11523493e+01,  4.06914817e-02, ...,\n",
       "          7.33496333e-01, -0.00000000e+00, -0.00000000e+00],\n",
       "        [ 6.27947045e+01,  5.75840072e+01,  2.47477160e-02, ...,\n",
       "          8.09859155e-01, -0.00000000e+00, -0.00000000e+00]],\n",
       "\n",
       "       [[ 4.35473889e+01,  4.99918151e+01, -3.45308502e-02, ...,\n",
       "          7.00035002e-02, -9.59183673e+01, -9.59183673e+01],\n",
       "        [ 4.23131452e+01,  4.95184668e+01, -3.85949952e-02, ...,\n",
       "          0.00000000e+00, -1.00000000e+02, -1.00000000e+02],\n",
       "        [ 4.23131452e+01,  4.95184668e+01, -3.81262711e-02, ...,\n",
       "         -1.04895105e-01, -1.00000000e+02, -7.42424242e+01],\n",
       "        ...,\n",
       "        [ 5.51332122e+01,  5.49014626e+01,  2.46902159e-02, ...,\n",
       "         -6.60410149e-01, -4.33333333e+01, -3.20987654e+01],\n",
       "        [ 6.50380532e+01,  5.93989895e+01,  4.02848734e-02, ...,\n",
       "         -2.42718447e-01, -1.09375000e+01, -8.64197531e+00],\n",
       "        [ 6.91577174e+01,  6.11523493e+01,  4.06914817e-02, ...,\n",
       "          7.33496333e-01, -0.00000000e+00, -0.00000000e+00]],\n",
       "\n",
       "       [[ 4.48582660e+01,  5.04805802e+01, -2.84291831e-02, ...,\n",
       "          6.99545296e-02, -9.06976744e+01, -9.18367347e+01],\n",
       "        [ 4.35473889e+01,  4.99918151e+01, -3.45308502e-02, ...,\n",
       "          7.00035002e-02, -9.59183673e+01, -9.59183673e+01],\n",
       "        [ 4.23131452e+01,  4.95184668e+01, -3.85949952e-02, ...,\n",
       "          0.00000000e+00, -1.00000000e+02, -1.00000000e+02],\n",
       "        ...,\n",
       "        [ 5.91364605e+01,  5.68906761e+01,  2.03038745e-02, ...,\n",
       "          3.84884535e-01, -2.50000000e+01, -1.85185185e+01],\n",
       "        [ 5.51332122e+01,  5.49014626e+01,  2.46902159e-02, ...,\n",
       "         -6.60410149e-01, -4.33333333e+01, -3.20987654e+01],\n",
       "        [ 6.50380532e+01,  5.93989895e+01,  4.02848734e-02, ...,\n",
       "         -2.42718447e-01, -1.09375000e+01, -8.64197531e+00]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0dab8603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.47438536e+01,  5.22925710e+01,  3.19560076e-02,\n",
       "         1.29118961e-02,  2.01197119e-02,  9.58333333e+01,\n",
       "         3.39582713e+01,  1.30695867e+00, -1.10344828e+00,\n",
       "        -2.78164117e-01, -1.25000000e+01, -2.53333333e+01],\n",
       "       [ 5.83344507e+01,  5.38667444e+01,  3.69707443e-02,\n",
       "         2.35914118e-02,  1.64491957e-02,  1.00000000e+02,\n",
       "         2.74617539e+01,  5.94613501e-01, -1.27016821e+00,\n",
       "         4.18994413e-01, -0.00000000e+00, -2.72727273e+01],\n",
       "       [ 5.42867625e+01,  5.17990665e+01,  3.13439704e-02,\n",
       "         2.22352626e-02,  4.15219123e-03,  9.44444444e+01,\n",
       "         2.32487281e+01,  5.97119775e-01, -2.65125765e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -4.85148515e+01],\n",
       "       [ 5.42867625e+01,  5.17990665e+01,  2.90971283e-02,\n",
       "         2.73903967e-02, -5.69679069e-03,  9.44444444e+01,\n",
       "         2.02643923e+01,  9.16138125e-01, -2.98102981e+00,\n",
       "         4.20757363e-01, -0.00000000e+00, -6.00000000e+01],\n",
       "       [ 5.03823943e+01,  4.97671601e+01,  2.04773445e-02,\n",
       "         2.57780627e-02, -2.00213289e-02,  8.23877069e+01,\n",
       "         1.77569296e+01,  4.93305144e-01, -2.96019054e+00,\n",
       "        -2.79720280e-01, -1.66666667e+01, -7.14285714e+01],\n",
       "       [ 5.31037494e+01,  5.11322960e+01,  1.50332484e-02,\n",
       "         3.11180150e-02, -3.13925207e-02,  5.46099291e+01,\n",
       "         1.63923241e+01,  1.49041874e+00, -1.75197527e+00,\n",
       "         6.33356791e-01, -0.00000000e+00, -6.57142857e+01],\n",
       "       [ 4.73443615e+01,  4.80885953e+01, -6.04576164e-03,\n",
       "         1.38185175e-02, -5.23391068e-02,  3.34717177e+01,\n",
       "         1.29637527e+01,  3.88555281e-01, -2.23598211e+00,\n",
       "         1.06685633e+00, -3.61702128e+01, -7.85714286e+01],\n",
       "       [ 3.54538743e+01,  4.24091509e+01, -2.40297121e-02,\n",
       "        -6.82512338e-03, -6.74065115e-02,  1.67702853e+01,\n",
       "         1.08208955e+01, -1.60951714e+00, -1.81564246e+00,\n",
       "        -7.41263678e-01, -1.00000000e+02, -1.00000000e+02],\n",
       "       [ 4.13342548e+01,  4.57367419e+01, -1.82019612e-02,\n",
       "         3.66551935e-03, -6.37743114e-02,  2.30504786e+01,\n",
       "         1.21970423e+01, -1.25479261e+00, -1.15143057e+00,\n",
       "         2.83185841e-01, -6.34146341e+01, -8.88059701e+01],\n",
       "       [ 3.77970007e+01,  4.41508212e+01, -2.52130899e-02,\n",
       "        -2.21632127e-03, -6.96738966e-02,  2.75220233e+01,\n",
       "         1.34629604e+01, -2.14755802e+00, -6.33134013e-01,\n",
       "        -2.11939244e-01, -8.62745098e+01, -9.47761194e+01],\n",
       "       [ 3.94005708e+01,  4.50897625e+01, -2.31405776e-02,\n",
       "         5.54081507e-03, -6.84728469e-02,  3.31222985e+01,\n",
       "         1.76560195e+01, -2.37931034e+00, -1.46188653e+00,\n",
       "        -9.79363414e-01, -8.11594203e+01, -9.02985075e+01],\n",
       "       [ 4.79435677e+01,  4.97834597e+01, -1.97429772e-02,\n",
       "         2.20823709e-02, -6.70232949e-02,  3.22184493e+01,\n",
       "         2.24582280e+01, -1.85375901e+00, -8.32466181e-01,\n",
       "         4.21496312e-01, -5.00000000e+01, -6.94029851e+01],\n",
       "       [ 4.31926443e+01,  4.75609762e+01, -4.03375205e-02,\n",
       "         8.06511517e-03, -8.17136800e-02,  2.05269071e+01,\n",
       "         2.62277948e+01, -3.22909585e+00, -1.35135135e+00,\n",
       "         3.17124736e-01, -6.94736842e+01, -7.83582090e+01],\n",
       "       [ 3.94633579e+01,  4.58535311e+01, -5.89001880e-02,\n",
       "        -8.00094017e-03, -9.07008365e-02,  1.03514685e+01,\n",
       "         3.32506076e+01, -3.86178862e+00, -1.01151029e+00,\n",
       "         0.00000000e+00, -8.38709677e+01, -8.50746269e+01],\n",
       "       [ 3.94633579e+01,  4.58535311e+01, -7.36353668e-02,\n",
       "        -2.51211566e-02, -9.28100429e-02,  4.97512438e+00,\n",
       "         4.17580702e+01, -3.43654304e+00, -1.56087409e+00,\n",
       "         7.09723208e-01, -8.50746269e+01, -8.50746269e+01],\n",
       "       [ 3.13514072e+01,  4.20706236e+01, -8.89002499e-02,\n",
       "        -5.34968717e-02, -9.11519532e-02,  0.00000000e+00,\n",
       "         5.02655329e+01, -3.19477843e+00, -2.25459591e+00,\n",
       "        -4.59201696e-01, -1.00000000e+02, -1.00000000e+02],\n",
       "       [ 3.40180994e+01,  4.39674328e+01, -7.96727777e-02,\n",
       "        -5.66718008e-02, -6.92993461e-02,  1.89393939e+00,\n",
       "         6.02655329e+01, -2.61437908e+00, -1.35888502e+00,\n",
       "        -9.44716585e-01, -1.00000000e+02, -1.00000000e+02],\n",
       "       [ 4.04492599e+01,  4.82606394e+01, -6.22870215e-02,\n",
       "        -5.00366805e-02, -4.26429093e-02,  1.06060606e+01,\n",
       "         7.02655329e+01, -2.09497207e-01,  2.10378682e-01,\n",
       "        -3.83408853e-01, -1.00000000e+02, -8.62385321e+01],\n",
       "       [ 4.34619908e+01,  5.01561553e+01, -4.91329371e-02,\n",
       "        -5.04317968e-02, -2.09059812e-02,  2.80372533e+01,\n",
       "         7.50962827e+01,  1.04675506e-01,  1.41392718e+00,\n",
       "        -6.23484586e-01, -9.43181818e+01, -7.61467890e+01],\n",
       "       [ 4.88167641e+01,  5.34176972e+01, -2.91840410e-02,\n",
       "        -4.25331884e-02,  3.61723516e-03,  4.75500417e+01,\n",
       "         7.92626857e+01,  1.54766092e+00,  1.90610660e+00,\n",
       "        -4.48275862e-01, -7.38636364e+01, -5.28455285e+01]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "942838c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(641, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4166cc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([304.,   6., 331.], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.numpy().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "32225dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(layers.SimpleRNN(units=5, activation=\"relu\", return_sequences=True))\n",
    "model.add(layers.SimpleRNN(units=5, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f294063",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "faed4a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_6 (SimpleRNN)    (None, 20, 5)             90        \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 5)                 55        \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 5)                 20        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183 (732.00 Byte)\n",
      "Trainable params: 173 (692.00 Byte)\n",
      "Non-trainable params: 10 (40.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "019f2a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([641, 3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "981bbe3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 20, 12)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = split_seq(test, STOCK)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8db1f8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 2s 18ms/step - loss: 1.3825 - accuracy: 0.2824 - val_loss: 13.0864 - val_accuracy: 0.0071\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1.3207 - accuracy: 0.3245 - val_loss: 7.0544 - val_accuracy: 0.0071\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.2581 - accuracy: 0.3370 - val_loss: 4.8231 - val_accuracy: 0.0071\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.2044 - accuracy: 0.3651 - val_loss: 3.5195 - val_accuracy: 0.0284\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 1.1458 - accuracy: 0.3916 - val_loss: 2.6798 - val_accuracy: 0.1773\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.1087 - accuracy: 0.4165 - val_loss: 2.3290 - val_accuracy: 0.2624\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1.0745 - accuracy: 0.4212 - val_loss: 1.8480 - val_accuracy: 0.3121\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.0324 - accuracy: 0.4571 - val_loss: 1.8920 - val_accuracy: 0.2411\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.9847 - accuracy: 0.4805 - val_loss: 1.8427 - val_accuracy: 0.1915\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.9584 - accuracy: 0.4992 - val_loss: 1.8971 - val_accuracy: 0.1348\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.9347 - accuracy: 0.5133 - val_loss: 1.9394 - val_accuracy: 0.1277\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.9094 - accuracy: 0.5476 - val_loss: 1.6642 - val_accuracy: 0.1418\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8937 - accuracy: 0.5460 - val_loss: 1.5212 - val_accuracy: 0.1418\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8751 - accuracy: 0.5460 - val_loss: 1.3820 - val_accuracy: 0.1773\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8542 - accuracy: 0.5569 - val_loss: 1.2831 - val_accuracy: 0.1702\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8414 - accuracy: 0.5585 - val_loss: 1.1958 - val_accuracy: 0.1986\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.8274 - accuracy: 0.5476 - val_loss: 1.1203 - val_accuracy: 0.2199\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.8159 - accuracy: 0.5554 - val_loss: 1.0344 - val_accuracy: 0.2553\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.8096 - accuracy: 0.5694 - val_loss: 1.0145 - val_accuracy: 0.2553\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7976 - accuracy: 0.5679 - val_loss: 0.9955 - val_accuracy: 0.2482\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7897 - accuracy: 0.5694 - val_loss: 0.9596 - val_accuracy: 0.2766\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7800 - accuracy: 0.5913 - val_loss: 0.9135 - val_accuracy: 0.3617\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.7760 - accuracy: 0.5757 - val_loss: 0.9086 - val_accuracy: 0.3191\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.7696 - accuracy: 0.5803 - val_loss: 0.8936 - val_accuracy: 0.3546\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7740 - accuracy: 0.5679 - val_loss: 0.8728 - val_accuracy: 0.3830\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.7707 - accuracy: 0.5585 - val_loss: 1.1271 - val_accuracy: 0.1560\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.7689 - accuracy: 0.5523 - val_loss: 1.1760 - val_accuracy: 0.1560\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.7647 - accuracy: 0.5601 - val_loss: 0.9689 - val_accuracy: 0.4043\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.7549 - accuracy: 0.5959 - val_loss: 0.8146 - val_accuracy: 0.6809\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.7528 - accuracy: 0.5788 - val_loss: 0.8502 - val_accuracy: 0.6170\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.7470 - accuracy: 0.5881 - val_loss: 0.7906 - val_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7462 - accuracy: 0.5835 - val_loss: 0.7633 - val_accuracy: 0.6738\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7421 - accuracy: 0.5928 - val_loss: 0.7599 - val_accuracy: 0.6596\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7441 - accuracy: 0.5944 - val_loss: 0.7488 - val_accuracy: 0.6738\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7396 - accuracy: 0.5881 - val_loss: 0.7484 - val_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7385 - accuracy: 0.5835 - val_loss: 0.7482 - val_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7339 - accuracy: 0.5850 - val_loss: 0.7206 - val_accuracy: 0.6596\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7376 - accuracy: 0.5788 - val_loss: 0.7461 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7331 - accuracy: 0.5850 - val_loss: 0.7345 - val_accuracy: 0.6809\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7318 - accuracy: 0.5975 - val_loss: 0.7517 - val_accuracy: 0.6383\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7310 - accuracy: 0.5881 - val_loss: 0.7272 - val_accuracy: 0.6738\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7300 - accuracy: 0.5959 - val_loss: 0.7280 - val_accuracy: 0.6738\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7297 - accuracy: 0.5772 - val_loss: 0.6992 - val_accuracy: 0.6738\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7282 - accuracy: 0.5975 - val_loss: 0.7270 - val_accuracy: 0.6738\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7278 - accuracy: 0.5959 - val_loss: 0.7339 - val_accuracy: 0.6596\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7269 - accuracy: 0.5819 - val_loss: 0.7143 - val_accuracy: 0.6738\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7260 - accuracy: 0.5881 - val_loss: 0.7383 - val_accuracy: 0.6383\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7239 - accuracy: 0.5803 - val_loss: 0.7709 - val_accuracy: 0.5816\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7262 - accuracy: 0.5959 - val_loss: 0.7963 - val_accuracy: 0.5603\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7282 - accuracy: 0.5835 - val_loss: 0.7121 - val_accuracy: 0.6809\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7265 - accuracy: 0.5850 - val_loss: 0.7273 - val_accuracy: 0.6383\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7236 - accuracy: 0.5819 - val_loss: 0.7100 - val_accuracy: 0.6809\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7231 - accuracy: 0.5913 - val_loss: 0.6878 - val_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7223 - accuracy: 0.5835 - val_loss: 0.6922 - val_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7211 - accuracy: 0.5928 - val_loss: 0.7042 - val_accuracy: 0.6738\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7184 - accuracy: 0.6053 - val_loss: 0.6990 - val_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7215 - accuracy: 0.5881 - val_loss: 0.7447 - val_accuracy: 0.6312\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7204 - accuracy: 0.5881 - val_loss: 0.7339 - val_accuracy: 0.6383\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7206 - accuracy: 0.5944 - val_loss: 0.6897 - val_accuracy: 0.6738\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7211 - accuracy: 0.5881 - val_loss: 0.7288 - val_accuracy: 0.6596\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7212 - accuracy: 0.5772 - val_loss: 0.8713 - val_accuracy: 0.3404\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7159 - accuracy: 0.5944 - val_loss: 0.6691 - val_accuracy: 0.6809\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7216 - accuracy: 0.5913 - val_loss: 0.6886 - val_accuracy: 0.6809\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7172 - accuracy: 0.5991 - val_loss: 0.6993 - val_accuracy: 0.6738\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7192 - accuracy: 0.5944 - val_loss: 0.7290 - val_accuracy: 0.6454\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7184 - accuracy: 0.6022 - val_loss: 0.6709 - val_accuracy: 0.6950\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7189 - accuracy: 0.5881 - val_loss: 0.7015 - val_accuracy: 0.6738\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7158 - accuracy: 0.5897 - val_loss: 0.7726 - val_accuracy: 0.5816\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7177 - accuracy: 0.5975 - val_loss: 0.6946 - val_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7143 - accuracy: 0.5928 - val_loss: 0.6990 - val_accuracy: 0.6596\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7175 - accuracy: 0.5835 - val_loss: 0.7664 - val_accuracy: 0.5957\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7164 - accuracy: 0.5803 - val_loss: 0.8240 - val_accuracy: 0.4468\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7161 - accuracy: 0.6022 - val_loss: 0.6683 - val_accuracy: 0.6879\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7140 - accuracy: 0.6053 - val_loss: 0.6197 - val_accuracy: 0.6596\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7169 - accuracy: 0.5819 - val_loss: 0.6736 - val_accuracy: 0.6950\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7134 - accuracy: 0.5897 - val_loss: 0.7157 - val_accuracy: 0.6525\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7143 - accuracy: 0.6084 - val_loss: 0.7173 - val_accuracy: 0.6525\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7162 - accuracy: 0.5881 - val_loss: 0.6806 - val_accuracy: 0.6738\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7158 - accuracy: 0.5897 - val_loss: 0.7551 - val_accuracy: 0.6170\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7138 - accuracy: 0.6037 - val_loss: 0.6968 - val_accuracy: 0.6525\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7136 - accuracy: 0.6147 - val_loss: 0.7263 - val_accuracy: 0.6454\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7122 - accuracy: 0.5975 - val_loss: 0.6644 - val_accuracy: 0.6809\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7136 - accuracy: 0.6022 - val_loss: 0.7330 - val_accuracy: 0.6454\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7090 - accuracy: 0.6053 - val_loss: 0.9328 - val_accuracy: 0.3121\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7115 - accuracy: 0.5975 - val_loss: 0.8350 - val_accuracy: 0.4823\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7123 - accuracy: 0.5991 - val_loss: 0.6509 - val_accuracy: 0.6809\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7112 - accuracy: 0.6069 - val_loss: 0.7103 - val_accuracy: 0.6454\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7133 - accuracy: 0.5991 - val_loss: 0.6353 - val_accuracy: 0.6596\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7139 - accuracy: 0.6006 - val_loss: 0.7141 - val_accuracy: 0.6454\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7077 - accuracy: 0.6006 - val_loss: 0.7219 - val_accuracy: 0.6383\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7092 - accuracy: 0.5881 - val_loss: 0.6554 - val_accuracy: 0.6738\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7129 - accuracy: 0.5897 - val_loss: 0.9860 - val_accuracy: 0.2340\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7072 - accuracy: 0.6100 - val_loss: 0.7886 - val_accuracy: 0.5532\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7096 - accuracy: 0.6131 - val_loss: 0.6457 - val_accuracy: 0.6596\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7048 - accuracy: 0.6053 - val_loss: 0.7017 - val_accuracy: 0.6454\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7108 - accuracy: 0.6006 - val_loss: 0.7250 - val_accuracy: 0.6383\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7108 - accuracy: 0.5928 - val_loss: 0.7796 - val_accuracy: 0.5603\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7092 - accuracy: 0.6147 - val_loss: 0.6466 - val_accuracy: 0.6596\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7100 - accuracy: 0.5928 - val_loss: 0.7353 - val_accuracy: 0.6312\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.7060 - accuracy: 0.6022 - val_loss: 0.7506 - val_accuracy: 0.6099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1aa9b6f73d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=30, epochs=100, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "595f4381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(141, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "02bf6f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07251374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75026226, -3.009335  ,  0.88172394],\n",
       "       [ 0.5935399 , -2.904694  ,  0.8976675 ],\n",
       "       [ 0.46936142, -2.8880348 ,  0.8683809 ],\n",
       "       [ 0.71156365, -2.7715511 ,  1.0378397 ],\n",
       "       [ 0.83951896, -2.693008  ,  1.1433342 ],\n",
       "       [ 0.92763263, -2.5985098 ,  1.23684   ],\n",
       "       [ 0.97284263, -2.7194872 ,  1.1692433 ],\n",
       "       [ 1.149591  , -2.8218803 ,  1.1624143 ],\n",
       "       [ 1.4220581 , -2.9210792 ,  1.1937597 ],\n",
       "       [ 1.7473078 , -2.9768543 ,  1.2759256 ],\n",
       "       [ 1.8694043 , -2.9455547 ,  1.3462951 ],\n",
       "       [ 1.8376219 , -2.757666  ,  1.4654431 ],\n",
       "       [ 1.6700172 , -2.5872474 ,  1.521216  ],\n",
       "       [ 1.0491991 , -2.4444876 ,  1.392717  ],\n",
       "       [ 0.9925151 , -2.2661304 ,  1.4942832 ],\n",
       "       [ 0.7935521 , -2.2261915 ,  1.4491739 ],\n",
       "       [ 0.76612425, -2.3633971 ,  1.3409548 ],\n",
       "       [ 0.8029171 , -2.6399064 ,  1.163785  ],\n",
       "       [ 0.790996  , -2.7159777 ,  1.1072257 ],\n",
       "       [ 0.76399857, -2.6472883 ,  1.1446757 ],\n",
       "       [ 0.6781429 , -2.440383  ,  1.2587752 ],\n",
       "       [ 0.5804916 , -2.204204  ,  1.3844869 ],\n",
       "       [ 0.51523286, -2.135179  ,  1.4134586 ],\n",
       "       [ 0.44337162, -2.0902367 ,  1.4223648 ],\n",
       "       [ 0.4201198 , -1.9830773 ,  1.4904103 ],\n",
       "       [ 0.15986454, -1.8677428 ,  1.474968  ],\n",
       "       [ 0.19462508, -1.811808  ,  1.5233076 ],\n",
       "       [ 0.39688987, -1.9518462 ,  1.4995952 ],\n",
       "       [ 0.60220575, -2.1918614 ,  1.4065388 ],\n",
       "       [ 1.0009421 , -2.5218215 ,  1.3237312 ],\n",
       "       [ 1.2861359 , -2.741187  ,  1.2736009 ],\n",
       "       [ 1.5779307 , -2.956293  ,  1.2337751 ],\n",
       "       [ 1.7470102 , -3.0221658 ,  1.2494935 ],\n",
       "       [ 1.7168422 , -2.9987378 ,  1.2520306 ],\n",
       "       [ 1.5601833 , -2.9516778 ,  1.222709  ],\n",
       "       [ 1.2882636 , -2.852006  ,  1.1913357 ],\n",
       "       [ 1.0283554 , -2.6901293 ,  1.2063544 ],\n",
       "       [ 0.9031684 , -2.5867949 ,  1.2332194 ],\n",
       "       [ 0.7977097 , -2.4665182 ,  1.2782393 ],\n",
       "       [ 0.7332636 , -2.3624918 ,  1.3274775 ],\n",
       "       [ 0.7347486 , -2.266168  ,  1.3959308 ],\n",
       "       [ 0.7518439 , -2.1738687 ,  1.4671655 ],\n",
       "       [ 0.8427719 , -2.1004448 ,  1.5535915 ],\n",
       "       [ 0.8551499 , -2.0005088 ,  1.630259  ],\n",
       "       [ 0.80483663, -1.8481902 ,  1.7196093 ],\n",
       "       [ 0.77229047, -1.6547698 ,  1.8431814 ],\n",
       "       [ 0.5008244 , -1.4913647 ,  1.8585162 ],\n",
       "       [ 0.6944856 , -1.4050856 ,  1.989818  ],\n",
       "       [ 0.7156467 , -1.4718137 ,  1.9547344 ],\n",
       "       [ 0.89256626, -1.5948619 ,  1.9327493 ],\n",
       "       [ 1.1372128 , -1.8505206 ,  1.8451899 ],\n",
       "       [ 1.3800111 , -2.16678   ,  1.712314  ],\n",
       "       [ 1.5572152 , -2.4919286 ,  1.5482072 ],\n",
       "       [ 1.8268502 , -2.7088203 ,  1.4945427 ],\n",
       "       [ 1.9947495 , -2.8204098 ,  1.4782534 ],\n",
       "       [ 2.0514288 , -2.7925224 ,  1.5164341 ],\n",
       "       [ 1.9426029 , -2.7138724 ,  1.5300397 ],\n",
       "       [ 2.0147383 , -2.6423903 ,  1.6069797 ],\n",
       "       [ 1.925379  , -2.5612068 ,  1.6299899 ],\n",
       "       [ 1.8116198 , -2.544074  ,  1.602329  ],\n",
       "       [ 1.964256  , -2.4956946 ,  1.6926882 ],\n",
       "       [ 2.2136207 , -2.510212  ,  1.7794026 ],\n",
       "       [ 2.2490678 , -2.4379659 ,  1.840266  ],\n",
       "       [ 2.2426696 , -2.4630966 ,  1.8232652 ],\n",
       "       [ 2.1847658 , -2.3319783 ,  1.8901716 ],\n",
       "       [ 2.2683818 , -2.2848    ,  1.9584645 ],\n",
       "       [ 2.3489609 , -2.1428304 ,  2.0830493 ],\n",
       "       [ 2.4438996 , -2.2366633 ,  2.052679  ],\n",
       "       [ 2.5430665 , -2.3203423 ,  2.0333586 ],\n",
       "       [ 2.6329322 , -2.3132296 ,  2.0726447 ],\n",
       "       [ 2.641488  , -2.307076  ,  2.0841515 ],\n",
       "       [ 2.6330745 , -2.2676396 ,  2.1107635 ],\n",
       "       [ 2.5030618 , -2.3125138 ,  2.0340574 ],\n",
       "       [ 2.5080435 , -2.4038167 ,  1.9733014 ],\n",
       "       [ 2.5901544 , -2.3593588 ,  2.029943  ],\n",
       "       [ 2.6559827 , -2.317688  ,  2.0800884 ],\n",
       "       [ 2.6706152 , -2.295837  ,  2.1011233 ],\n",
       "       [ 2.6214209 , -2.3162446 ,  2.0720809 ],\n",
       "       [ 2.6053379 , -2.2499528 ,  2.1189919 ],\n",
       "       [ 2.3911767 , -2.0900133 ,  2.149829  ],\n",
       "       [ 2.306433  , -2.0570068 ,  2.1410375 ],\n",
       "       [ 2.0153706 , -2.0454865 ,  2.0454786 ],\n",
       "       [ 1.4833233 , -1.8897932 ,  1.9563122 ],\n",
       "       [ 1.762521  , -1.8548121 ,  2.085207  ],\n",
       "       [ 2.0487702 , -1.8214424 ,  2.2115483 ],\n",
       "       [ 2.1801612 , -1.9020096 ,  2.2033443 ],\n",
       "       [ 2.0270293 , -1.9792414 ,  2.0931668 ],\n",
       "       [ 2.01964   , -2.0610113 ,  2.0323005 ],\n",
       "       [ 2.0934212 , -2.1647677 ,  1.9875066 ],\n",
       "       [ 2.1881206 , -2.205434  ,  1.9940232 ],\n",
       "       [ 2.230598  , -2.2445304 ,  1.9829377 ],\n",
       "       [ 2.2991447 , -2.2298784 ,  2.018442  ],\n",
       "       [ 2.314175  , -2.1903596 ,  2.0511916 ],\n",
       "       [ 2.328998  , -2.2386594 ,  2.020347  ],\n",
       "       [ 2.3499103 , -2.3969774 ,  1.9168869 ],\n",
       "       [ 2.3379128 , -2.6045928 ,  1.7695539 ],\n",
       "       [ 2.3338444 , -2.6903396 ,  1.7021488 ],\n",
       "       [ 2.2708077 , -2.8245335 ,  1.5800598 ],\n",
       "       [ 2.2424576 , -2.9161777 ,  1.5005702 ],\n",
       "       [ 1.765033  , -3.0406537 ,  1.2490168 ],\n",
       "       [ 2.0563757 , -2.9594765 ,  1.4153503 ],\n",
       "       [ 2.0336738 , -2.711207  ,  1.5817575 ],\n",
       "       [ 2.028472  , -2.4578059 ,  1.7565942 ],\n",
       "       [ 1.9623573 , -2.3303452 ,  1.8197346 ],\n",
       "       [ 2.0554178 , -2.3632388 ,  1.8345542 ],\n",
       "       [ 2.0722585 , -2.311317  ,  1.8785151 ],\n",
       "       [ 2.0594535 , -2.193993  ,  1.954821  ],\n",
       "       [ 2.111678  , -2.1862268 ,  1.9790485 ],\n",
       "       [ 2.1567848 , -2.2547245 ,  1.9483061 ],\n",
       "       [ 2.1522365 , -2.3366892 ,  1.8883779 ],\n",
       "       [ 2.188518  , -2.460816  ,  1.8138603 ],\n",
       "       [ 2.1644583 , -2.611178  ,  1.6990685 ],\n",
       "       [ 2.1656985 , -2.7852683 ,  1.5785153 ],\n",
       "       [ 2.1949463 , -2.8544421 ,  1.5365003 ],\n",
       "       [ 2.2933152 , -2.8281965 ,  1.5831354 ],\n",
       "       [ 2.3782036 , -2.8051262 ,  1.62371   ],\n",
       "       [ 2.4071565 , -2.8214278 ,  1.6185622 ],\n",
       "       [ 2.4155045 , -2.809546  ,  1.6301037 ],\n",
       "       [ 2.413667  , -2.7718177 ,  1.6592553 ],\n",
       "       [ 2.3978426 , -2.7063446 ,  1.7065027 ],\n",
       "       [ 2.3643634 , -2.6573381 ,  1.7361453 ],\n",
       "       [ 2.3325999 , -2.5820413 ,  1.7847948 ],\n",
       "       [ 2.292323  , -2.4221377 ,  1.8814131 ],\n",
       "       [ 2.2278078 , -2.3518066 ,  1.9050288 ],\n",
       "       [ 2.1951056 , -2.412489  ,  1.8503046 ],\n",
       "       [ 2.2238889 , -2.5381684 ,  1.7724723 ],\n",
       "       [ 2.017174  , -2.649715  ,  1.6174572 ],\n",
       "       [ 1.4064198 , -2.6946125 ,  1.3601152 ],\n",
       "       [ 1.2861512 , -2.759684  ,  1.2700179 ],\n",
       "       [ 1.2113247 , -2.7688527 ,  1.2353811 ],\n",
       "       [ 1.1085212 , -2.750184  ,  1.2120559 ],\n",
       "       [ 1.1006098 , -2.6446233 ,  1.2820237 ],\n",
       "       [ 0.8833426 , -2.5579152 ,  1.263866  ],\n",
       "       [ 0.90515035, -2.4899526 ,  1.3178012 ],\n",
       "       [ 0.8280375 , -2.5030284 ,  1.281234  ],\n",
       "       [ 0.7143293 , -2.4932075 ,  1.2466043 ],\n",
       "       [ 0.7646455 , -2.4843848 ,  1.2732422 ],\n",
       "       [ 0.7716801 , -2.4311385 ,  1.3136084 ],\n",
       "       [ 1.0383298 , -2.3946185 ,  1.4372038 ],\n",
       "       [ 1.2309994 , -2.3811874 ,  1.5173807 ],\n",
       "       [ 1.3585361 , -2.4073768 ,  1.5440936 ]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "89eabe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label = np.argmax(y_pred, axis=1)\n",
    "y_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "af00ac74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_label = np.argmax(y_test, axis=1)\n",
    "y_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "880bed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6099290780141844\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_true=y_test_label, y_pred=y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28fef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algothonDep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
