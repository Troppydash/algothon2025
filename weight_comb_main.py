import numpy as np
import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
import statsmodels.api as sm

NAME = "Weight_combination"
positions = []
currentPos = np.zeros(50)

def getMyPosition(prices):
    global currentPos, positions
    df = pd.DataFrame(prices.T, columns=np.arange(50))

    # Testing diff_evol weights (dual annealing gives lower correlation, and ends up with all [1] after tuning).
    # Trained on [0:1000], predicting on [1000:1500]. Terry's original optim func 
    # start 1000
    # mean(PL): 42.4
    # return: 0.00066
    # StdDev(PL): 212.13
    # annSharpe(PL): 3.16
    # totDvolume: 32148401
    # Score: 21.23
    # weights = np.array([-9.99925371e-01, -2.68425677e-02, -1.17435236e-02, -9.80035456e-04,
    #    -2.87847866e-01, -9.98553622e-01, -1.55903512e-03, -2.25884277e-01,
    #    -2.90641281e-01, -1.09641324e-01, -2.60593308e-01, -1.95272802e-01,
    #    -4.84680823e-01, -9.99806776e-01, -1.78517533e-01, -2.25449529e-01,
    #    -8.01128697e-01, -9.97869278e-01, -4.59408234e-03, -9.99924677e-01,
    #    -9.97999150e-01, -9.98676284e-01, -2.40232548e-01, -2.75923076e-01,
    #    -6.06011611e-01, -2.85172169e-01, -8.89712522e-04, -9.98086931e-01,
    #    -7.46842409e-02, -3.11112645e-01,  7.64032022e-04, -2.17810259e-01,
    #    -4.48163719e-01, -9.99685881e-01, -5.66833422e-01, -6.77963156e-01,
    #    -4.60064461e-01, -3.67033909e-01, -9.99220016e-01, -9.99202993e-01,
    #    -4.60275365e-03, -4.03132792e-01, -2.59480269e-01, -3.99291175e-04,
    #    -5.12487731e-01, -9.98588735e-01, -3.65608970e-01, -9.99235975e-01,
    #    -3.93944159e-01, -9.89829421e-01]) * -1
    
    # Trained on [0:1000], predicting on [1000:1500]. New entropy optim func
    # start 1000
    # mean(PL): 38.1
    # return: 0.00085
    # StdDev(PL): 159.58
    # annSharpe(PL): 3.77
    # totDvolume: 22370105
    # Score: 22.11
    # weights = [0.7946489989036388, 0.0, 0.0, 0.0, 0.16908224781892703, 0.4985597846467912, 0.0, 0.15291790489077386, 0.13277790341784612, 0.048509047245111764, 0.110684047363089, 0.10676307469753794, 0.2239639990652197, 0.49604411040291696, 0.12525976175014059, 0.1338700341341299, 0.4031271393294091, 0.5176252693974414, 0.0, 0.9994965107486131, 0.3238192557180066, 0.5144782895202605, 0.13258585403281672, 0.14636506004773844, 0.29464896524682965, 0.14499384744035257, 0.0, 0.5109030648948872, 0.04039220535155705, 0.14913767184257806, 0.0, 0.10437235027801324, 0.2328596285854919, 0.8925421290837453, 0.33807851303250896, 0.3552513564770508, 0.23681124371077406, 0.20061480318413136, 0.7680740662855916, 0.49678282905152826, 0.0, 0.23225834918991786, 0.1495154093255376, 0.0, 0.23383899460259064, 0.434296827971261, 0.1807002499163193, 0.7970222437868314, 0.1833652962155419, 0.39087366471789964]

    # Trained on [750:1000], predicting on [250:750]. New entropy optim func
    # start 250
    # mean(PL): 36.9
    # return: 0.00091
    # StdDev(PL): 168.79
    # annSharpe(PL): 3.45
    # totDvolume: 20159000
    # Score: 19.99
    # weights = [0.8788576944653246, 0.0, 0.0, 0.17058986587004465, 0.0, 0.0, 0.5934195473796684, 0.530893432332016, 0.0, 0.0, 0.0, 0.22653867343523462, 0.0, 0.6692738170391314, 0.18940481054042885, 0.40935483661525934, 0.3550454436906874, 0.8294186669266953, 0.0, 1.0, 0.0, 0.594121020176415, 0.008853732844558104, 0.15329035363300655, 0.16921470765463612, 0.2269145928932162, 0.0, 0.820555198623961, 0.01799613284814738, 0.0, 0.0, 0.1156357937081359, 0.23683081383113985, 0.9334736502343832, 0.39415472051833156, 0.20379139009703018, 0.2988538023804927, 0.3220859026301105, 0.921493540261803, 0.5261526151446795, 0.07717411925594041, 0.23480511512358357, 0.0, 0.0, 0.49526613884099363, 0.0, 0.12228242092376415, 0.0, 0.3083685344430369, 0.4569819544507672]

    # Trained on 0:750
    # Tested on 750:1250
    # start 250
    # mean(PL): 55.9
    # return: 0.00159
    # StdDev(PL): 159.18
    # annSharpe(PL): 5.56
    # totDvolume: 17625214
    # Score: 40.02
    weights = [0.5573754464523868, 0.0, 0.0, 0.0, 0.13480283214516636, 0.41603001349721913, 0.0, 0.05692390227762912, 0.14563371557930951, 0.063933741758815, 0.18061046477903667, 0.10747174358093155, 0.30937586373290876, 0.3748159127879655, 0.14642033836979368, 0.0, 0.3614114965072213, 0.44116586387454426, 0.0, 0.9417999791436065, 0.3862243662376045, 0.4913313838543852, 0.12202629055860266, 0.13903187287914814, 0.2578870903487207, 0.19671607960802953, 0.10110760594719194, 0.4071002722619753, 0.058777912874493514, 0.14392284579586842, 0.0, 0.14501582673101893, 0.26419433391505226, 1.0, 0.2448083516476498, 0.3597755812614899, 0.20547083699698204, 0.14325953654525356, 0.7674369123756909, 0.5213347216633265, 0.0, 0.20238767017383683, 0.19159521412854133, 0.0, 0.1902642680918194, 0.6571538457653346, 0.13856126222065268, 0.8297061010827315, 0.1091183692033961, 0.2568403477132902]


    # weights = [0.9993368525940594, 0.14789945296769336, 0.038515145069382584, 0.0017356271571431492, 0.27343129700530877, 0.996171034494997, 0.12079461933710434, 0.23946927037250987, 0.27309640010955416, 0.1277154895419601, 0.25056077735106363, 0.2037980676858897, 0.5211630683530846, 0.9929964025320182, 0.19724839483729228, 0.3330950351355684, 0.7329854936259874, 0.9998889688236812, 0.04815774442299947, 0.9990796154425072, 0.9923260281422368, 0.9921923467957958, 0.2495801971156011, 0.29451496277749944, 0.5681381252388418, 0.3234408300580345, 0.00014230686595251285, 0.9057728895194996, 0.09097955207890607, 0.3417556750766235, -0.0015437511811802196, 0.22094171790118455, 0.4058223672504244, 0.999507807256371, 0.56983662659397, 0.6457454318548805, 0.4347793071419135, 0.3433392115959286, 0.9999938457937518, 0.9980620094348795, 0.028720048991166536, 0.4340253077760887, 0.29593490157043334, 0.0004264321313471875, 0.48023544442000476, 0.9986115004734968, 0.3484091439882988, 0.9997777824507015, 0.34927805741771545, 0.5462439143410758]
    tickers = list(range(50))
    limit = [0] * 50
    for i in tickers:
        limit[i] = (10000 // df[i].values[-1])

    # desired = [0] * 50
    # for amount in range(int(limit[0]), 0, -1):
    #     desired[0] = amount
    #     for i in tickers[1:]:
    #         # check if possible
    #         wanted = int(amount / weights[0] * weights[i])
    #         if abs(wanted) <= limit[i]:
    #             desired[i] = wanted
    #         else:
    #             break
    #     else:
    #         # ok
    #         break
    low_comp = 1000000
    for i in range(50):
        if abs(weights[i]) < 0.000001:
            continue
        low_comp = min(low_comp, int(limit[i]/abs(weights[i])))
    

    prices = df
    weighted = (prices * weights)[tickers].sum(1)
    myModel = ARIMA(weighted.pct_change().iloc[-250:], order=(1, 0, 0)).fit()
    esp_return = myModel.forecast().values[-1]

    cost = 0.0005
    for i in tickers:
        if abs(esp_return) > cost:
            if esp_return > 0:
                currentPos[i] = low_comp * weights[i] 
            else:
                currentPos[i] = -low_comp * weights[i]
        else:
            if esp_return * currentPos[i] < 0:
                currentPos[i] = 0

    # positions.append(currentPos.tolist())

    # if len(positions) == 500:
    #     pos = pd.DataFrame(positions, columns=list(range(50)))
    #     pos.to_csv('pos.dump', sep='\t', index=False,header=False)
    return np.copy(currentPos)
